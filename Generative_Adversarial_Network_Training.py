# -*- coding: utf-8 -*-
"""Generative Adversarial Network Training

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qg-Zlc6GiJSLu7GXUdZovmq5P2s8YXJS
"""

# Commented out IPython magic to ensure Python compatibility.
## import packages
import torch
import random
import numpy as np
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.data import sampler
import torchvision.datasets as dset
import os
import numpy.testing as npt
#from torchsummary import summary

import matplotlib.pyplot as plt
# %matplotlib inline
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

random.seed(0)
np.random.seed(0)
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
os.environ['PYTHONHASHSEED'] = '0'

import torchvision
import torchvision.transforms as transforms
import os

root = './data/'
if not os.path.isdir(root):
    os.mkdir(root)

train_bs = 128

# Data transformation for the DataLoader - normalizes to between [-1,1]
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])])
training_data = torchvision.datasets.MNIST(root, train=True, transform=transform,download=True)
train_loader = torch.utils.data.DataLoader(dataset=training_data, batch_size=train_bs, shuffle=True, drop_last=True)

def noise(bs, dim):
    out = (torch.randn((bs, dim)))
    if is_cuda:
        out = out.cuda()
    return out

class Generator(nn.Module):
    def __init__(self, noise_dim=100, out_size=784):
        super(Generator, self).__init__()
        
        self.layer1 = nn.Linear(noise_dim, 256)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)
        self.layer2 = nn.Linear(256, 512)
        self.layer3 = nn.Linear(512, 1024)
        self.layer4 = nn.Linear(1024, out_size)
        self.tanh = nn.Tanh()
        
        
    def forward(self, x):

        x = self.self.layer1(x)
        x = self.leaky_relu(x)
        x = self.self.layer2(x)
        x = self.leaky_relu(x)
        x = self.self.layer3(x)
        x = self.leaky_relu(x)
        x = self.self.layer4(x)
        x = self.tanh(x)
        x = x.view(x.shape[0], 1, 28, 28)
        return x

# Initialize the Generator and move it to GPU (if is_cuda)
generator = Generator()
print(generator)
if is_cuda:
    generator = generator.cuda()

class Discriminator(nn.Module):
    def __init__(self, input_size=784):
        super(Discriminator, self).__init__()
        self.fc1 = nn.Linear(input_size, 512)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 1)
    
    def forward(self, x):
        x = x.view(x.shape[0], -1)
        x = self.fc1(x)
        x = self.leaky_relu(x)
        x = self.fc2(x)
        x = self.leaky_relu(x)
        y = self.fc3(x)
        
        return y

bce_loss = nn.BCEWithLogitsLoss()

def DLoss(logits_real, logits_fake, targets_real, targets_fake):
    logits = torch.cat((logits_real, logits_fake), dim=0)
    targets = torch.cat((targets_real, targets_fake), dim=0)
    loss = bce_loss(logits, targets)
    return loss

def GLoss(logits_fake, targets_real):
    g_loss = bce_loss(logits_fake, targets_real)
    
    return g_loss

#Generated realistic images
epochs = 40
noise_dim = 100
LR = 0.0002
optimizer_G = torch.optim.Adam(generator.parameters(), lr=LR, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LR, betas=(0.5, 0.999))

## Training loop

for epoch in range(epochs):
    for i, (images, _) in enumerate(train_loader):
        print(i, epoch)
        targets_real = (torch.FloatTensor(images.size(0), 1).uniform_(0.8, 1.0))
        targets_fake = (torch.FloatTensor(images.size(0), 1).uniform_(0.0, 0.2))
                
        if is_cuda:
            targets_real = targets_real.cuda()
            targets_fake = targets_fake.cuda()
            images = images.cuda()
            
        optimizer_D.zero_grad()
        logits_real = discriminator(images)

        g_fake_seed = noise(train_bs, noise_dim)
        
        fake_images = generator(g_fake_seed).detach()
        logits_fake = discriminator(fake_images.view(train_bs, 1, 28, 28))

        d_total_error = DLoss(logits_real, logits_fake, targets_real, targets_fake)
        d_total_error.backward()        
        optimizer_D.step()

        optimizer_G.zero_grad()
        g_fake_seed = noise(train_bs, noise_dim)
        fake_images = generator(g_fake_seed)

        gen_logits_fake = discriminator(fake_images.view(train_bs, 1, 28, 28))
        g_error = GLoss(gen_logits_fake, targets_real)
        g_error.backward()
        optimizer_G.step()

    print("Epoch:  ", epoch)
    print("D Loss: ", d_total_error.item())
    print("G Loss: ", g_error.item())
          
    if epoch % 2 == 0:
        viz_batch = fake_images.data.cpu().numpy()
        viz_batch = viz_batch[:100,:,:,:]
        viz_batch = viz_batch.reshape(-1,28*28).squeeze()
        viz_batch = viz_batch.reshape(10,10, 28,28).transpose(0,2,1,3).reshape(28*10,-1)

        plt.figure(figsize = (8,8))
        plt.axis('off')
        plt.imshow(viz_batch, cmap='gray')
        plt.show()